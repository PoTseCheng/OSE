{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "source": [
    "function Num_Stab_Approx"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "RM=6\n",
    "penalty= 7\n",
    "normalised= 1\n",
    "X(1:T-1,:)= trial 4 datax\n",
    "y(1:T-1,:)=trial 4 datay\n",
    "X is generated assuming d=1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"trial4_x.csv\", encoding = \"ISO-8859-1\")\n",
    "add=test.columns.tolist()\n",
    "test.loc[-1] = add \n",
    "test.index = test.index + 1  \n",
    "test= test.sort_index()\n",
    "test.columns=[\"blah\",\"blah2\",\"blah3\"]\n",
    "x = np.copy(test)\n",
    "\n",
    "test = pd.read_csv(\"trial4_y.csv\", encoding = \"ISO-8859-1\")\n",
    "add=test.columns.tolist()\n",
    "test.loc[-1] = add \n",
    "test.index = test.index + 1  \n",
    "test= test.sort_index()\n",
    "test.columns=[\"blah\"]\n",
    "y= np.copy(test)\n",
    "y[0] = float(y[0])\n",
    "x[0] = [1., 48.29917764394355828, 1.]"
   ]
  },
  {
   "source": [
    "Function begin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM = 6\n",
    "penalty= 7 \n",
    "normalised= 1"
   ]
  },
  {
   "source": [
    "Function body"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = x.shape[0]\n",
    "n = x.shape[1]\n",
    "N = y.shape[1] #Compute the number of columns in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalised == 1 or RM >= 5:\n",
    "    \n",
    "    X1 = np.divide(\n",
    "    (x[:,1:n] - np.matmul(np.ones((T, 1)), x[:,1:n].mean(axis=0).reshape(1, n-1))),\n",
    "    np.matmul(np.ones((T, 1)), np.array([np.std(x[:,i], ddof=1) for i in range(1,n)]).reshape(1,n-1))\n",
    "    )\n",
    "    X1 = X1.astype(float)\n",
    "    #unfortunately np.std seems cannot return an array for each column, therefore I was forced to use a list comprehension here\n",
    "    \n",
    "    Y1 = np.divide(\n",
    "    (y - np.ones((T,1))*np.mean(y)),\n",
    "    np.matmul(np.ones((T,1)), np.std(y, ddof=1).reshape(1,1))\n",
    "    )\n",
    "    Y1 = Y1.astype(float)\n",
    "    n1 = n-1 # Number of coefficients in a regression with normalized data is reduced by 1 (no intercept)\n",
    "else:\n",
    "\n",
    "    X1 = x\n",
    "    Y1 = Y          # Leave Y without changes\n",
    "    n1 = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.divide(\n",
    "    (x[:,1:n] - np.matmul(np.ones((T, 1)), x[:,1:n].mean(axis=0).reshape(1, n-1))),\n",
    "    np.matmul(np.ones((T, 1)), np.array([np.std(x[:,i], ddof=1) for i in range(1,n)]).reshape(1,n-1))\n",
    "    ) \n",
    "X1 = X1.astype(float)\n",
    "    #unfortunately np.std seems cannot return an array for each column, therefore I was forced to use a list comprehension here\n",
    "Y1 = np.divide(\n",
    "    (y - np.ones((T,1))*np.mean(y)),\n",
    "    np.matmul(np.ones((T,1)), np.std(y, ddof=1).reshape(1,1))\n",
    "    )\n",
    "Y1 = Y1.astype(float)\n",
    "n1 = n-1 # Number of coefficients in a regression with normalized data is reduced by 1 (no intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Regression methods\n",
    "#simple OLS\n",
    "if RM == 1:\n",
    "    B = np.matmul(\n",
    "        inv(np.matmul(X1.transpose(),X1).astype(float)), #need to convert the output to float or else return error\n",
    "        np.matmul(X1.transpose(),Y1)\n",
    "        )\n",
    "#LS-SVD\n",
    "elif RM == 2:\n",
    "    U, S, V = svd(X1, full_matrices=False) #The minus is in the opposite side compared to matlab, but should not have a difference in result\n",
    "    S_inv = np.diag(1/S)\n",
    "    B = np.matmul(np.matmul(np.matmul(V,S_inv),U.transpose()),Y1) #The B will have the same value but will be upside down compared to matlab as a result\n",
    "\n",
    "#check if changes result or not###\n",
    "\n",
    "#LAD-PP\n",
    "elif RM == 3:\n",
    "    \n",
    "    # #This method is strongly discouraged! It is one of the slowest among all other regression\n",
    "    # #construct the boundaries\n",
    "    BND = [(-100, 100)]*n1 + [(0, float(\"inf\"))]*2*T\n",
    "    f = [0]*n1+ [1]*2*T\n",
    "    #specify the Aeq an beq\n",
    "    Aeq = np.concatenate((X1, np.identity(T), -np.identity(T)), axis=1)\n",
    "    B =[]\n",
    "    #solve the equation\n",
    "    for j in range(N):\n",
    "        beq = Y1[:,j].tolist()\n",
    "        result = linprog(f, A_eq = Aeq, b_eq = beq, bounds= BND , method='revised simplex')\n",
    "        B.append(result.x) \n",
    "    \n",
    "    #Or so it should. Unfortunately, the Scipy package will took ages to even finish computing one optimisation solution given the size of Aeq and beq. Without other choices, I import the function that does this part of computation from matlab, which is able to finish the computation within seconds.\n",
    "\n",
    "# LAD-DP\n",
    "elif RM == 4:\n",
    "#Possibily also very slow\n",
    "#Define Boundary\n",
    "BND = [(-1,1)]*T\n",
    "\n",
    "#Define aeq and beq for linprog\n",
    "Aeq = X1.transpose()\n",
    "beq = np.zeros((n1, 1))\n",
    "B = []\n",
    "for i in range(N):\n",
    "    f = -Y1[:,i]\n",
    "    lamda = linprog(f, A_eq = Aeq, b_eq = beq, bounds= BND)\n",
    "    B.append(lamda)\n",
    "\n",
    "#RLS-Tikhonov\n",
    "elif RM == 5:\n",
    "\n",
    "# RLS-TSVD\n",
    "elif RM == 6:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = svd(X1, full_matrices=False) #The minus is in the opposite side compared to matlab, but should not have a difference in result\n",
    "S_inv = np.diag(1/S)\n",
    "B = np.matmul(np.matmul(np.matmul(V,S_inv),U.transpose()),Y1) #The B will have the same value but will be upside down compared to matlab as a result\n",
    "\n",
    "#check if changes result or not###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "test tmr"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rm == 4\n",
    "#Define Boundary\n",
    "BND = [(-1,1)]*T\n",
    "\n",
    "#Define aeq and beq for linprog\n",
    "Aeq = X1.transpose()\n",
    "beq = np.zeros((n1, 1))\n",
    "B = []\n",
    "for i in range(N):\n",
    "    f = -Y1[:,i]\n",
    "    lamda = linprog(f, A_eq = Aeq, b_eq = beq, bounds= BND)\n",
    "    B.append(lamda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 9.99999989, -2.99999999])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "res.x"
   ]
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## This notebook aims to develope the Accuracy testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tools.auxiliary import*\n",
    "from tools.GH_Quadrature import*\n",
    "from tools.Ord_Herm_Pol_1 import*\n",
    "from tools.Num_Stab_Approx import*\n",
    "from tools.Main_Results import*\n",
    "from tools.Accuracy_Test_1 import*\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from statistics import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =reading(\"epsi10000.csv\")\n",
    "T  = 10000           #Choose the simulation length for the solution procedure, T<=10,000                    \n",
    "gam     = 1        # Utility-function parameter\n",
    "alpha   = 0.36     # Capital share in output\n",
    "beta    = 0.99     # Discount factor\n",
    "delta   = 0.02     # Depreciation rate \n",
    "rho     = 0.95     # Persistence of the log of the productivity level\n",
    "sigma   = 0.01    # Standard deviation of shocks to the log of the productivity level\n",
    "ks = ( (1-beta+beta*delta) / (alpha*beta) )**(1/(alpha-1) )\n",
    "k = np.array([ks]*(T+1))\n",
    "a= [1]*(T)\n",
    "epsi = df.iloc[:,0].astype(float)*sigma\n",
    "epsi=epsi.tolist()\n",
    "for i in range(1, T):\n",
    "    a[i]=a[i-1]**(rho)*math.exp(epsi[i])\n",
    "a=np.asarray(a)\n",
    "kdamp = 0.01    \n",
    "dif_GSSA_1d = 1e+10  \n",
    "bk_1d  = np.array([0., 0.95, ks*0.05])\n",
    "bk_1d= np.reshape(bk_1d, (3,1))\n",
    "k_old = [ks+1]*(T+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "y= GSSA_main_cycle(T, gam, alpha, beta, delta, kdamp, dif_GSSA_1d, a, bk_1d, k_old, k)\n",
    "end = time.time()\n",
    "elapsed_time = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape((y.shape[0],1)) #make sure y is in the right shape\n",
    "#The GSSA parameters\n",
    "\n",
    "kdamp = 0.1\n",
    "dif_GSSA_D = 1e+10\n",
    "\n",
    "#The matrices of the polynomial coefficients\n",
    "D_max  = 5 #because of python\n",
    "npol = np.array([3, 6, 10, 15, 21])\n",
    "\n",
    "# 13. Choose an integration method for computing solutions  \n",
    "IM  = 10\n",
    "\n",
    "n_nodes,epsi_nodes, weight_nodes= GH_Quadrature(Qn=10, N=1, vcv=sigma**2)\n",
    "\n",
    "#make sure to change a into the right shape\n",
    "a = np.reshape(a, (T, 1))\n",
    "a1 = np.matmul(np.power(a,rho), np.exp(epsi_nodes.transpose()))\n",
    "\n",
    "#14. Choose a regression specification \n",
    "RM = 6           # Choose a regression method: \n",
    "                 # 1=OLS,          2=LS-SVD,   3=LAD-PP,  4=LAD-DP, \n",
    "                 # 5=RLS-Tikhonov, 6=RLS-TSVD, 7=RLAD-PP, 8=RLAD-DP\n",
    "normalize = 1    # Option of normalizing the data; 0=unnormalized data; \n",
    "                 # 1=normalized data                    \n",
    "penalty = 7      # Degree of regularization for a regularization methods, \n",
    "                 # RM=5,6,7,8 (must be negative, e.g., -7 for RM=5,7,8 \n",
    "                 # and must be positive, e.g., 7, for RM=6)\n",
    "PF = 0           # Choose a polynomial family; 0=Ordinary (default);  \n",
    "                 # 1=Hermite\n",
    "# 15. Initialize the capital series\n",
    "zb = np.matrix([[np.mean(k[0:T]), np.mean(a[0:T])], [np.std(k[0:T]), np.std(a[0:T])]])\n",
    "z = np.concatenate((k[0:T].reshape(T,1), a[0:T].reshape(T,1)), axis=1)\n",
    "k_old = [ks+1]*(T+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BK = []\n",
    "Time = []\n",
    "for d in range(1, D_max+1):\n",
    "    start = time.time()\n",
    "    BK.append(GSSA_poly(T, a, z, d, PF, zb, RM, penalty, normalize, dif_GSSA_D, kdamp, alpha, beta, delta, k, gam, y, k_old, a1, IM, n_nodes, weight_nodes, checker= 0))\n",
    "    end = time.time()\n",
    "    Time.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1.76699623],\n",
       "       [ 0.97049037],\n",
       "       [ 3.19294961]])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "BK[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "BK[0].shape"
   ]
  },
  {
   "source": [
    "## Accuracy:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_test = 10200\n",
    "\n",
    "df =reading(\"epsi_test.csv\")\n",
    "epsi_test = sigma*df.to_numpy().astype(float)\n",
    "a_test = [1]\n",
    "for i in range(1,T_test):\n",
    "    value = a_test[i-1]**(rho)*math.exp(float(epsi_test[i]))\n",
    "    a_test.append(value)\n",
    "\n",
    "IM_test = 10\n",
    "\n",
    "k_test = [ks]\n",
    "result_max = []\n",
    "result_mean = []\n",
    "result_time = []\n",
    "for d in range(1, D_max+1):\n",
    "    #refressing k_test to make sure that k_test is always 10200\n",
    "    #k_test = [ks]\n",
    "    for i in range(T_test):\n",
    "        X_test = Ord_Herm_Pol_1(np.array([k_test[i], a_test[i]]).reshape([1,2]),d,PF,zb) # D = 1 for now, we will plug this in another for loop\n",
    "        value = float(np.matmul(X_test, BK[d-1]))\n",
    "        k_test.append(value)\n",
    "\n",
    "        # testing it below\n",
    "    discard = 200 #new defined value\n",
    "    mean_error, max_error, error_time = Accuracy_Test_1(sigma,rho,beta,gam,alpha,delta,k_test,a_test,BK[d-1],d,IM_test,PF,zb,discard)\n",
    "    result_max.append(max_error)\n",
    "    result_mean.append(mean_error)\n",
    "    result_time.append(error_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(1, D_max+1):\n",
    "    #refressing k_test to make sure that k_test is always 10200\n",
    "    #k_test = [ks]\n",
    "    for i in range(T_test):\n",
    "        X_test = Ord_Herm_Pol_1(np.array([k_test[i], a_test[i]]).reshape([1,2]),d,PF,zb) # D = 1 for now, we will plug this in another for loop\n",
    "        value = float(np.matmul(X_test, BK[d-1]))\n",
    "        k_test.append(value)\n",
    "\n",
    "        # testing it below\n",
    "    discard = 200 #new defined value\n",
    "    mean_error, max_error, error_time = Accuracy_Test_1(sigma,rho,beta,gam,alpha,delta,k_test,a_test,BK[d-1],d,IM_test,PF,zb,discard)\n",
    "    result_max.append(max_error)\n",
    "    result_mean.append(mean_error)\n",
    "    result_time.append(error_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "for i in range(T_test):\n",
    "    X_test = Ord_Herm_Pol_1(np.array([k_test[i], a_test[i]]).reshape([1,2]),d,PF,zb) # D = 1 for now, we will plug this in another for loop\n",
    "    value = float(np.matmul(X_test, BK[d-1]))\n",
    "    k_test.append(value)\n",
    "\n",
    "        # testing it below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discard = 200 #new defined value\n",
    "mean_error, max_error, error_time = Accuracy_Test_1(sigma,rho,beta,gam,alpha,delta,k_test,a_test,BK[d-1],d,IM_test,PF,zb,discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "k0 = float(k[0])\n",
    "a0 = float(a[0])\n",
    "k1 = float(Ord_Herm_Pol_1(np.array([k0,a0]).reshape((1,2)), d, PF=PF, zb=zb)@BK[0])\n",
    "c0 = k0**alpha*a0 - k1+ (1-delta)*k0\n",
    "a1 = a0**rho*np.exp(epsi_nodes)\n",
    "k1_dupl1 = k1*np.ones((n_nodes,1))\n",
    "x1 = Ord_Herm_Pol_1(np.concatenate((k1_dupl1, a1), axis=1),d,PF,zb)\n",
    "k2 = x1@BK[0]\n",
    "c1 = k1**alpha*a1 - k2 + (1-delta)*k1\n",
    "test.append(weight_nodes.conj().transpose()@(beta*c1**(-gam)/c0**(-gam)*(1-delta+alpha*a1*k1**(alpha-1))) -1)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Prerequisite:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Testing area:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy_Test_1(sigma,rho,beta,gam,alpha,delta,k,a,bk,D,IM,PF,zb,discard):\n",
    "    '''\n",
    "    '''\n",
    "    start = time.time()\n",
    "    n_nodes,epsi_nodes, weight_nodes = GH_Quadrature(Qn=IM, N=1, vcv=sigma**2)\n",
    "    #initialise empty list\n",
    "    errors = []\n",
    "    for i in range(len(a)):\n",
    "        k0 = float(k[i])\n",
    "        a0 = float(a[i])\n",
    "        k1 = float(Ord_Herm_Pol_1(np.array([k0,a0]).reshape((1,2)), D, PF=PF, zb=zb)@bk)\n",
    "        c0 = k0**alpha*a0 - k1+ (1-delta)*k0\n",
    "        a1 = a0**rho*np.exp(epsi_nodes)\n",
    "        k1_dupl1 = k1*np.ones((n_nodes,1))\n",
    "        x1 = Ord_Herm_Pol_1(np.concatenate((k1_dupl1, a1), axis=1),D,PF,zb)\n",
    "        k2 = np.matmul(x1, bk)\n",
    "        c1 = k1**alpha*a1 - k2 + (1-delta)*k1\n",
    "        errors.append(weight_nodes.conj().transpose()@(beta*c1**(-gam)/c0**(-gam)*(1-delta+alpha*a1*k1**(alpha-1))) -1) #testing new approach\n",
    "    Error_means = math.log10(np.mean(np.mean(np.abs(errors[discard:]))))\n",
    "    Error_max = math.log10(np.max(np.max(np.abs(errors[discard:]))))\n",
    "    end = time.time()\n",
    "    time_test = end - start\n",
    "    return Error_means, Error_max, time_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(a):\n",
    "    k0 = float(k[i])\n",
    "    a0 = float(a[i,0])\n",
    "    k1 = float(np.matmul(Ord_Herm_Pol_1(np.array([k0,a0]).reshape((1,2)), D, PF=PF, zb=zb), bk))\n",
    "    c0 = k0**alpha*a0 - k1+ (1-delta)*k0\n",
    "    a1 = a0**rho*np.exp(epsi_nodes)\n",
    "    k1_dup1 = k1*np.ones((n_nodes,1))\n",
    "    x1 = Ord_Herm_Pol_1(np.concatenate((k1_dupl1, a1), axis=1),D,PF,zb)\n",
    "    k2 = np.matmul(x1, bk)\n",
    "    c1 = k1**alpha*a1 - k2 + (1-delta)*k1\n",
    "    errors.append(weight_nodes.conj().transpose()@(beta*c1**(-gam)/c0**(-gam)*(1-delta+alpha@a1*k1**(alpha-1))) ) #testing new approach\n",
    "Error_means = math.log10(mean(mean(abs(errors[discard:]))))\n",
    "Error_max = math.log10(max(max(abs(errors[discard:]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "    i = 1\n",
    "    k0 = float(k[i])\n",
    "    a0 = float(a[i,0])\n",
    "    k1 = float(np.matmul(Ord_Herm_Pol_1(np.array([k0,a0]).reshape((1,2)), D=1, PF=PF, zb=zb), BK[0]))\n",
    "    c0 = k0**alpha*a0 - k1+ (1-delta)*k0\n",
    "    a1 = a0**rho*np.exp(epsi_nodes)\n",
    "    k1_dupl1 = k1*np.ones((n_nodes,1))\n",
    "    x1 = Ord_Herm_Pol_1(np.concatenate((k1_dupl1, a1), axis=1), 1, PF, zb)\n",
    "    k2 = np.matmul(x1, BK[0])\n",
    "    c1 = k1**alpha*a1 - k2 + (1-delta)*k1\n",
    "    errors = weight_nodes.conj().transpose()@(beta*c1**(-gam)/c0**(-gam)*(1-delta+alpha*a1*k1**(alpha-1))) -1 #testing new approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.98793406],\n",
       "       [0.99112902],\n",
       "       [0.99385936],\n",
       "       [0.99638101],\n",
       "       [0.9987996 ],\n",
       "       [1.0011802 ],\n",
       "       [1.00357767],\n",
       "       [1.00605495],\n",
       "       [1.00871185],\n",
       "       [1.01178787]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "beta*c1**(-gam)/c0**(-gam)*(1-delta+alpha*a1*k1**(alpha-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_nodes'*(beta*c1(1:n_nodes,1).^(-gam)./c0(1,1).^(-gam).*(1-delta+alpha*a1(1:n_nodes,1).*k1(1,1).^(alpha-1)))-1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": []
  }
 ]
}